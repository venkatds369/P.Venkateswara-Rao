{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text classifcation model - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # operating system \n",
    "import pandas as pd # pandas\n",
    "import numpy as np # numpy \n",
    "import re # regular expressions in python \n",
    "import nltk # natural language tool kit ,data cleaning \n",
    "from nltk.corpus import stopwords # 4. to remove stop words\n",
    "from nltk.stem import WordNetLemmatizer # 5. lematization \n",
    "from nltk.stem.porter import * # Stemmers remove morphological affixes from words, leaving only the word stem.\n",
    "from sklearn.feature_extraction.text import CountVectorizer # term frequency  tokenise the collection of text documents and build a vocabulary of known words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # N( TF) or N(TF* IDF)Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # tO CONVERT count vectorizer to Tfidf Transform a count matrix to a normalized tf or tf-idf representation\n",
    "from itertools import islice # Functions creating iterators for efficient looping. the islice() function works much the same way as slicing a list or tuple\n",
    "from sklearn.naive_bayes import MultinomialNB # multi label target variables \n",
    "import pickle#Any object in python can be pickled so that it can be saved on disk.Pickling is a way to convert a python object (list, dict, etc.) into a character stream.\n",
    "#It is used for serializing and de-serializing a Python object structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\admin\\\\Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 6 columns):\n",
      "Class        120000 non-null int64\n",
      "ShortDesc    120000 non-null object\n",
      "Desc         120000 non-null object\n",
      "cleaned      120000 non-null object\n",
      "stemmed      120000 non-null object\n",
      "lemmed       120000 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  \\\n",
       "0  3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1  3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2  3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3  3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4  3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                   2  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()# either u can use both of them ( 1  or 2  as inputs ( independent features))\n",
    "#0 is target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 3 columns):\n",
      "0    120000 non-null int64\n",
      "1    120000 non-null object\n",
      "2    120000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                Desc  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [\"Class\",\"ShortDesc\",\"Desc\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a full list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "# a.) convert all words to  lower case\n",
    "# b.) Remove special characters ,numbers (use regular expressions )[! A-Z  a-z]\n",
    "# c.) Remove stop words\n",
    "# d.) Additionally we can use lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')#  how to get ad_ stop words? By using Document Term Matrix , with least  term frequency we can keep in stop words \n",
    "ad_stopwords = ['monday', 'like', 'com', 'use', 'help', 'create', 'time', 'want', 'a', 'about', 'above', 'across', 'after', 'afterwards'] \n",
    "stops.extend(ad_stopwords)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('(Monday).*?(April).*?(4).*?(2016).*?(10:16:06)', re.IGNORECASE|re.DOTALL)\n",
      "<re.Match object; span=(0, 32), match='Monday, April, 4, 2016, 10:16:06'>\n",
      "Monday\n",
      "Monday\n",
      "April\n",
      "4\n",
      "2016\n",
      "10:16:06\n",
      "<re.Match object; span=(0, 32), match='Monday, April, 4, 2016, 10:16:06'>\n"
     ]
    }
   ],
   "source": [
    "##REGEX FOR DATE REMOVAL\n",
    "#import re\n",
    "txt='Monday, April, 4, 2016, 10:16:06'\n",
    "re1='(Monday)'\t# Day Of Week 1\n",
    "re2='.*?'\t# Non-greedy match on filler\n",
    "re3='(April)'\t# Month 1\n",
    "re4='.*?'\t# Non-greedy match on filler\n",
    "re5='(4)'\t# Day 1\n",
    "re6='.*?'\t# Non-greedy match on filler\n",
    "re7='(2016)'\t# Year 1\n",
    "re8='.*?'\t# Non-greedy match on filler\n",
    "re9='(10:16:06)'\t# HourMinuteSec 1\n",
    "\n",
    "rg = re.compile(re1+re2+re3+re4+re5+re6+re7+re8+re9,re.IGNORECASE|re.DOTALL)\n",
    "print(rg)\n",
    "m = rg.search(txt)\n",
    "print(m)\n",
    "if m:\n",
    "    dayofweek1=m.group(1)\n",
    "    print(dayofweek1)\n",
    "    print(m.group(1))\n",
    "    \n",
    "    month1=m.group(2)\n",
    "    print(month1)\n",
    "    day1=m.group(3)\n",
    "    print(day1)\n",
    "    year1=m.group(4)\n",
    "    print(year1)\n",
    "    time1=m.group(5)\n",
    "    print(time1)\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('(b).*?(4\\\\/04\\\\/2016)', re.IGNORECASE|re.DOTALL)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "re1='(b)'\t# Variable Name 1\n",
    "re2='.*?'\t# Non-greedy match on filler\n",
    "re3='(4\\\\/04\\\\/2016)'\t# DDMMYYYY 1\n",
    "\n",
    "rd = re.compile(re1+re2+re3,re.IGNORECASE|re.DOTALL)\n",
    "print(rd)\n",
    "m = rd.search(txt)\n",
    "print(m)\n",
    "if m:\n",
    "    var1=m.group(1)\n",
    "    print(var1)\n",
    "    \n",
    "    ddmmyyyy1=m.group(2)\n",
    "    print(ddmmyyyy1)\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('(\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\r____________________________\\\\\\\\\\\\\\\\r)', re.IGNORECASE|re.DOTALL)\n",
      "<re.Match object; span=(0, 37), match='\\\\\\\\r\\\\\\\\r____________________________\\\\\\\\r'>\n",
      "\\\\r\\\\r____________________________\\\\r\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "txt='\\\\\\\\r\\\\\\\\r____________________________\\\\\\\\r'\n",
    "\n",
    "re1='(\\\\\\\\\\\\\\\\r\\\\\\\\\\\\\\\\r____________________________\\\\\\\\\\\\\\\\r)'\t# Windows UNC 1\n",
    "\n",
    "rt = re.compile(re1,re.IGNORECASE|re.DOTALL)\n",
    "print(rt)\n",
    "m = rt.search(txt)\n",
    "print(m)\n",
    "\n",
    "if m:\n",
    "    unc1=m.group(1)\n",
    "    print(unc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemm=wordnetlemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk # doubt\n",
    "def _remove_noise(input_text):\n",
    "    input_text = str(input_text).encode('ascii', 'ignore')# there are some when we are encoding  entire text to ascii , only special charecters are predefined\n",
    "    # like japanese  and other languages it can not convert to ascii ,there are non as\n",
    "    input_text = str(input_text).replace(\",\", \"\")\n",
    "    input_text = str(input_text).replace(\"\\'\" ,\"\")\n",
    "    input_text = str(input_text).replace(\"\\\\\", \"\")\n",
    "    input_text = str(input_text).replace(\"-\", \"\")\n",
    "    input_text = str(input_text).replace(\".\", \"\")\n",
    "    input_text = re.sub(\"\\d+\",\"\",input_text)\n",
    "    input_text = re.sub(\"[^a-zA-Z0-9]\",\" \",input_text)\n",
    "    words      =str(input_text).split()\n",
    "    noise_free_words =  [word for word in words if word.lower() not in stops]\n",
    "    lower_words =[word.lower() for word in noise_free_words]\n",
    "    lower_words=[lemm.lemmatize(w) for w in lower_words]\n",
    "                                         \n",
    "    return lower_words   \n",
    "    #input_text = str(input_text).replace(\"\\'\\\\\", \"\")\n",
    "    #input_text = str(input_text).replace(\"\\'\\\", \"\")\n",
    "    #input_text = re.sub(rg, ' ', input_text)# sub ---- substitute \n",
    "    \n",
    "    #input_text = re.sub([[:punct:]], '', input_text) -- this is a step in R \n",
    "    #input_text = re.sub(rd, ' ', input_text)\n",
    "     \n",
    "    #input_text = re.sub(rt, ' ', input_text)\n",
    "      \n",
    "    #words = str(input_text).split()\n",
    "    #pos_words = nltk.pos_tag(words)\n",
    "    #noise_free_words = [i[0] for i in pos_words if i[1] in ('NN')]\n",
    "   # noise_free_words = [word for word in noise_free_words if word.lower() not in stops]\n",
    "   # return noise_free_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"This is a Test to remove numbers\\.1234\\.. and special characters 1234@%!\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_remove_noise(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bthis', 'test', 'remove', 'number', 'special', 'character']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_remove_noise(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>[b, reuters, shortsellers, wall, street, dwind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>[breuters, private, investment, firm, carlyle,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>[breuters, soaring, crude, price, plus, worrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>[breuters, authority, halted, oil, exportflows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>[bafp, tearaway, world, oil, price, toppling, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  Reuters - Private investment firm Carlyle Grou...   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3  Reuters - Authorities have halted oil export\\f...   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  [b, reuters, shortsellers, wall, street, dwind...  \n",
       "1  [breuters, private, investment, firm, carlyle,...  \n",
       "2  [breuters, soaring, crude, price, plus, worrie...  \n",
       "3  [breuters, authority, halted, oil, exportflows...  \n",
       "4  [bafp, tearaway, world, oil, price, toppling, ...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned\"] = df.Desc.apply(_remove_noise)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    b reuters shortsellers wall street dwindlingba...\n",
       "1    breuters private investment firm carlyle group...\n",
       "2    breuters soaring crude price plus worriesabout...\n",
       "3    breuters authority halted oil exportflows main...\n",
       "4    bafp tearaway world oil price toppling record ...\n",
       "Name: lemmed, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmed'] = df.cleaned.map(lambda x: ' '.join([lemmatizer.lemmatize(y) for y in x]))\n",
    "df.lemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words= stops, min_df=.001, max_df=.7, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cvec.fit(df['lemmed'])\n",
    "len(cvec.vocabulary_)\n",
    "# term frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reuters', 2852),\n",
       " ('wall', 3649),\n",
       " ('street', 3264),\n",
       " ('green', 1476),\n",
       " ('wall street', 3650),\n",
       " ('breuters', 489),\n",
       " ('private', 2608),\n",
       " ('investment', 1739),\n",
       " ('firm', 1298),\n",
       " ('making', 2021),\n",
       " ('play', 2509),\n",
       " ('defense', 943),\n",
       " ('industry', 1679),\n",
       " ('quietly', 2697),\n",
       " ('another', 158),\n",
       " ('part', 2418),\n",
       " ('market', 2047),\n",
       " ('soaring', 3133),\n",
       " ('crude', 876),\n",
       " ('price', 2595)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from itertools import islice\n",
    "cvec.fit(df.lemmed)\n",
    "\n",
    "list(islice(cvec.vocabulary_.items(), 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (120000, 3800)\n",
      "nonzero count: 1921427\n",
      "sparsity: 0.42%\n"
     ]
    }
   ],
   "source": [
    "cvec_counts = cvec.transform(df.lemmed)\n",
    "print ('sparse matrix shape:', cvec_counts.shape)\n",
    "print ('nonzero count:', cvec_counts.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * cvec_counts.nnz / (cvec_counts.shape[0] * cvec_counts.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<120000x3800 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1921427 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformed_weights = transformer.fit_transform(cvec_counts)\n",
    "transformed_weights\n",
    "\n",
    "#transformer = TfidfTransformer()\n",
    "#loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"feature.pkl\", \"rb\")))\n",
    "#tfidf = transformer.fit_transform(loaded_vec.fit_transform(cvec_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>said</td>\n",
       "      <td>0.018048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>new</td>\n",
       "      <td>0.015668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>bthe</td>\n",
       "      <td>0.012961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>year</td>\n",
       "      <td>0.012489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>quot</td>\n",
       "      <td>0.012422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>company</td>\n",
       "      <td>0.011498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>reuters</td>\n",
       "      <td>0.010348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>first</td>\n",
       "      <td>0.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>two</td>\n",
       "      <td>0.009680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>world</td>\n",
       "      <td>0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>wednesday</td>\n",
       "      <td>0.009114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>tuesday</td>\n",
       "      <td>0.008985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>thursday</td>\n",
       "      <td>0.008885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>one</td>\n",
       "      <td>0.008758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>friday</td>\n",
       "      <td>0.008510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>game</td>\n",
       "      <td>0.008392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>yesterday</td>\n",
       "      <td>0.008365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>week</td>\n",
       "      <td>0.008341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>inc</td>\n",
       "      <td>0.008157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>state</td>\n",
       "      <td>0.008108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term    weight\n",
       "2917       said  0.018048\n",
       "2233        new  0.015668\n",
       "532        bthe  0.012961\n",
       "3780       year  0.012489\n",
       "2700       quot  0.012422\n",
       "763     company  0.011498\n",
       "2852    reuters  0.010348\n",
       "1299      first  0.010254\n",
       "3535        two  0.009680\n",
       "3743      world  0.009401\n",
       "3688  wednesday  0.009114\n",
       "3524    tuesday  0.008985\n",
       "3445   thursday  0.008885\n",
       "2336        one  0.008758\n",
       "1390     friday  0.008510\n",
       "1409       game  0.008392\n",
       "3784  yesterday  0.008365\n",
       "3691       week  0.008341\n",
       "1651        inc  0.008157\n",
       "3225      state  0.008108"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cvec.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(transformed_weights, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\admin\\\\Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"test.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3                  Fears for T N pension after talks   \n",
       "1      4  The Race is On: Second Private Team Sets Launc...   \n",
       "2      4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4      4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "\n",
       "                                                Desc  \n",
       "0  Unions representing workers at Turner   Newall...  \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
       "2  AP - A company founded by a chemistry research...  \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
       "4  AP - Southern California's smog-fighting agenc...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns = [\"Class\",\"ShortDesc\",\"Desc\"]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>[b, union, representing, worker, turner, newal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>[bspacecom, toronto, canada, secondteam, rocke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>[bap, company, founded, chemistry, researcher,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>[b, ap, barely, dawn, mike, fitzpatrick, start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>[b, ap, southern, california, smogfighting, ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3                  Fears for T N pension after talks   \n",
       "1      4  The Race is On: Second Private Team Sets Launc...   \n",
       "2      4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4      4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  Unions representing workers at Turner   Newall...   \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   \n",
       "2  AP - A company founded by a chemistry research...   \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   \n",
       "4  AP - Southern California's smog-fighting agenc...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  [b, union, representing, worker, turner, newal...  \n",
       "1  [bspacecom, toronto, canada, secondteam, rocke...  \n",
       "2  [bap, company, founded, chemistry, researcher,...  \n",
       "3  [b, ap, barely, dawn, mike, fitzpatrick, start...  \n",
       "4  [b, ap, southern, california, smogfighting, ag...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"cleaned\"] = df1.Desc.apply(_remove_noise)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    b union representing worker turner newall say ...\n",
       "1    bspacecom toronto canada secondteam rocketeers...\n",
       "2    bap company founded chemistry researcher unive...\n",
       "3    b ap barely dawn mike fitzpatrick start shift ...\n",
       "4    b ap southern california smogfighting agency w...\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df1['stemmed'] = df1.cleaned.map(lambda x: ' '.join([lemmatizer.lemmatize(y) for y in x]))\n",
    "df1.stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec1 = CountVectorizer(stop_words= stops, min_df=0.001, max_df=0.9, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('union', 3668),\n",
       " ('representing', 2897),\n",
       " ('worker', 3854),\n",
       " ('say', 3036),\n",
       " ('talk', 3460),\n",
       " ('parent', 2482),\n",
       " ('firm', 1350),\n",
       " ('federal', 1298),\n",
       " ('bspacecom', 539),\n",
       " ('toronto', 3574),\n",
       " ('canada', 598),\n",
       " ('competing', 790),\n",
       " ('million', 2178),\n",
       " ('ansari', 161),\n",
       " ('prize', 2693),\n",
       " ('contest', 837),\n",
       " ('space', 3273),\n",
       " ('flight', 1377),\n",
       " ('officially', 2387),\n",
       " ('announced', 153)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from itertools import islice\n",
    "cvec1.fit(df1.stemmed)\n",
    "list(islice(cvec1.vocabulary_.items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3916"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec1 = CountVectorizer(stop_words=stops, min_df=.001, max_df=.8, ngram_range=(1,2))\n",
    "cvec1.fit(df1.stemmed)\n",
    "len(cvec1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (7600, 3800)\n",
      "nonzero count: 120410\n",
      "sparsity: 0.42%\n"
     ]
    }
   ],
   "source": [
    "cvec_counts1 = cvec.transform(df1.stemmed)\n",
    "print ('sparse matrix shape:', cvec_counts1.shape)\n",
    "print ('nonzero count:', cvec_counts1.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * cvec_counts1.nnz / (cvec_counts1.shape[0] * cvec_counts1.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7600x3800 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 120410 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer1 = TfidfTransformer()\n",
    "transformed_weights1 = transformer.fit_transform(cvec_counts1)\n",
    "transformed_weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nb.predict(transformed_weights1)# new TFIDF values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1664,   76,   92,   68],\n",
       "       [  39, 1817,   13,   31],\n",
       "       [  96,   26, 1524,  254],\n",
       "       [  94,   50,  173, 1583]], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df1[\"Class\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668421052631579"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df1[\"Class\"], preds, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
